{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-built architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. LeNet 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This research was published in `1998`, you can go through the paper [here](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](TL1.png \"LeNet5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Q1. In the above architecture, what is the filter size in the first CONV layer (consider no padding and stride = 1)?\n",
    "<br>Q2. What is the `filter` and `stride` size in the first `Subsampling` (Pooling) layer?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This architecture has `60k` parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. AlexNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This paper was published in 2012. You can go through the paper [here](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](TL2.png \"AlexNet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This architecture has ~60M parameters. This architecture was trained on [IMAGE NET](http://www.image-net.org/) dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. VGG - 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This paper was published in 2015. You can go through the paper [here](https://arxiv.org/pdf/1409.1556.pdf). VGG architecture has fixed the lot of hyper-parameters unlike the `AlexNet` as shown above. VGG - 16 architecure used following hyper-parameters - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **CONV Layer**: 3x3 filter, stride = 1 and `same` padding\n",
    "- **POOLING Layer:** 2x2 filter, stride = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](TL3.png \"VGG 16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This architecture was also trained on `ImageNet` dataset and has `138 M` parameters. Below table shows various versions of VGG architecture -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](TL4.png \"VGG 16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Q3. What happens if we want to build a deeper network than VGG architecture? What problem we might face?</font>\n",
    "<br><font color='red'>Q4. If you want to build e.g. 1000 layer network, what you need to do?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Res Nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This paper was also published in 2015. You can go through the paper [here](https://arxiv.org/pdf/1512.03385.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](TL6.png \"Residual Networks Block\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](TL5.png \"Residual Networks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](TL7.png \"Transfer Learning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](TL8.png \"Transfer Learning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also `add new layers` in the above architecture. There is no such rule/technique which tells you how much layers should we freeze or how many new layers should we add? These are hyper-parameters and this is an art or you need to be creative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, if you want to use the above pre-trained VGG architecture weights trained on ImageNet data to a completely different task, then you can try out following architectures and train your new model and see how it works- \n",
    "- Freeze all layers except for the final convolutional layer of VGG16\n",
    "- Freeze all layers except the final convolutional layer of VGG16, and add several dense (fully connected) layers\n",
    "- Freeze all layers except the final convolutional layer of VGG16, and add several dense (fully connected) layers with dropout\n",
    "- and many more different architectures based on your creativity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71cd5bf9",
   "metadata": {
    "id": "a1af8f38"
   },
   "source": [
    "## Context: \n",
    "McCurr Healthcare Consultancy is an MNC that has thousands of employees spread out across the globe. The company believes in hiring the best talent available and retaining them for as long as possible. A huge amount of resources is spent on retaining existing employees through various initiatives. The Head of People Operations wants to bring down the cost of retaining employees. For this, he proposes limiting the incentives to only those employees who are at risk of attrition. As a recently hired Data Scientist in the People Operations Department, you have been asked to identify patterns in characteristics of employees who leave the organization. Also, you have to use this information to predict if an employee is at risk of attrition. This information will be used to target them with incentives.\n",
    "\n",
    "## Objective : \n",
    "\n",
    "* To identify the different factors that drive attrition\n",
    "* To make a model to predict if an employee will attrite or not\n",
    "\n",
    "\n",
    "## Dataset :\n",
    "\n",
    "The data contains demographic details, work-related metrics and attrition flag.\n",
    "\n",
    "* **EmployeeNumber** - Employee Identifier\n",
    "* **Attrition** - Did the employee attrite?\n",
    "* **Age** - Age of the employee\n",
    "* **BusinessTravel** - Travel commitments for the job\n",
    "* **DailyRate** - Data description not available**\n",
    "* **Department** - Employee Department\n",
    "* **DistanceFromHome** - Distance from work to home (in km)\n",
    "* **Education** - 1-Below College, 2-College, 3-Bachelor, 4-Master,5-Doctor\n",
    "* **EducationField** - Field of Education\n",
    "* **EnvironmentSatisfaction** - 1-Low, 2-Medium, 3-High, 4-Very High\n",
    "* **Gender** - Employee's gender\n",
    "* **HourlyRate** - Data description not available**\n",
    "* **JobInvolvement** - 1-Low, 2-Medium, 3-High, 4-Very High\n",
    "* **JobLevel** - Level of job (1 to 5)\n",
    "* **JobRole** - Job Roles\n",
    "* **JobSatisfaction** - 1-Low, 2-Medium, 3-High, 4-Very High\n",
    "* **MaritalStatus** - Marital Status\n",
    "* **MonthlyIncome** - Monthly Salary\n",
    "* **MonthlyRate** - Data description not available**\n",
    "* **NumCompaniesWorked** - Number of companies worked at\n",
    "* **Over18** - Over 18 years of age?\n",
    "* **OverTime** - Overtime?\n",
    "* **PercentSalaryHike** - The percentage increase in salary last year\n",
    "* **PerformanceRating** - 1-Low, 2-Good, 3-Excellent, 4-Outstanding\n",
    "* **RelationshipSatisfaction** - 1-Low, 2-Medium, 3-High, 4-Very High\n",
    "* **StandardHours** - Standard Hours\n",
    "* **StockOptionLevel** - Stock Option Level\n",
    "* **TotalWorkingYears** - Total years worked\n",
    "* **TrainingTimesLastYear** - Number of training attended last year\n",
    "* **WorkLifeBalance** - 1-Low, 2-Good, 3-Excellent, 4-Outstanding\n",
    "* **YearsAtCompany** - Years at Company\n",
    "* **YearsInCurrentRole** - Years in the current role\n",
    "* **YearsSinceLastPromotion** - Years since the last promotion\n",
    "* **YearsWithCurrManager** - Years with the current manager\n",
    "\n",
    "**In the real world, you will not find definitions for some of your variables. It is a part of the analysis to figure out what they might mean**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8a7eae",
   "metadata": {
    "id": "d6700f10"
   },
   "source": [
    "### Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45e44c70",
   "metadata": {
    "id": "d60f33c8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#to scale the data using z-score \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#algorithms to use\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#Metrics to evaluate the model\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_curve\n",
    "\n",
    "#for tuning the model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#to ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385c47ac",
   "metadata": {
    "id": "91a960cf"
   },
   "source": [
    "### Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "930c6cd9",
   "metadata": {
    "id": "ff29bb95"
   },
   "outputs": [],
   "source": [
    "#reading the dataset\n",
    "df = pd.read_excel('HR_Employee_Attrition_Dataset.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "362097ba",
   "metadata": {
    "id": "6cc2e7f0",
    "outputId": "6d9d4fe1-754b-461c-a7b7-ae862ad32bcf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EmployeeNumber</th>\n",
       "      <th>Attrition</th>\n",
       "      <th>Age</th>\n",
       "      <th>BusinessTravel</th>\n",
       "      <th>DailyRate</th>\n",
       "      <th>Department</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationField</th>\n",
       "      <th>EnvironmentSatisfaction</th>\n",
       "      <th>...</th>\n",
       "      <th>RelationshipSatisfaction</th>\n",
       "      <th>StandardHours</th>\n",
       "      <th>StockOptionLevel</th>\n",
       "      <th>TotalWorkingYears</th>\n",
       "      <th>TrainingTimesLastYear</th>\n",
       "      <th>WorkLifeBalance</th>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <th>YearsInCurrentRole</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>41</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1102</td>\n",
       "      <td>Sales</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "      <td>49</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>279</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>37</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1373</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Other</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>33</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>1392</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>No</td>\n",
       "      <td>27</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>591</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Medical</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   EmployeeNumber Attrition  Age     BusinessTravel  DailyRate  \\\n",
       "0               1       Yes   41      Travel_Rarely       1102   \n",
       "1               2        No   49  Travel_Frequently        279   \n",
       "2               3       Yes   37      Travel_Rarely       1373   \n",
       "3               4        No   33  Travel_Frequently       1392   \n",
       "4               5        No   27      Travel_Rarely        591   \n",
       "\n",
       "               Department  DistanceFromHome  Education EducationField  \\\n",
       "0                   Sales                 1          2  Life Sciences   \n",
       "1  Research & Development                 8          1  Life Sciences   \n",
       "2  Research & Development                 2          2          Other   \n",
       "3  Research & Development                 3          4  Life Sciences   \n",
       "4  Research & Development                 2          1        Medical   \n",
       "\n",
       "   EnvironmentSatisfaction  ... RelationshipSatisfaction  StandardHours  \\\n",
       "0                        2  ...                        1             80   \n",
       "1                        3  ...                        4             80   \n",
       "2                        4  ...                        2             80   \n",
       "3                        4  ...                        3             80   \n",
       "4                        1  ...                        4             80   \n",
       "\n",
       "   StockOptionLevel  TotalWorkingYears TrainingTimesLastYear  WorkLifeBalance  \\\n",
       "0                 0                  8                     0                1   \n",
       "1                 1                 10                     3                3   \n",
       "2                 0                  7                     3                3   \n",
       "3                 0                  8                     3                3   \n",
       "4                 1                  6                     3                3   \n",
       "\n",
       "  YearsAtCompany  YearsInCurrentRole  YearsSinceLastPromotion  \\\n",
       "0              6                   4                        0   \n",
       "1             10                   7                        1   \n",
       "2              0                   0                        0   \n",
       "3              8                   7                        3   \n",
       "4              2                   2                        2   \n",
       "\n",
       "   YearsWithCurrManager  \n",
       "0                     5  \n",
       "1                     7  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     2  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041a24c5",
   "metadata": {
    "id": "f367a777"
   },
   "source": [
    "### Printing the information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbf9bdd4",
   "metadata": {
    "id": "e366b601",
    "outputId": "7aeb37b3-a85d-49a0-ad18-3306a7fd84cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2940 entries, 0 to 2939\n",
      "Data columns (total 34 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   EmployeeNumber            2940 non-null   int64 \n",
      " 1   Attrition                 2940 non-null   object\n",
      " 2   Age                       2940 non-null   int64 \n",
      " 3   BusinessTravel            2940 non-null   object\n",
      " 4   DailyRate                 2940 non-null   int64 \n",
      " 5   Department                2940 non-null   object\n",
      " 6   DistanceFromHome          2940 non-null   int64 \n",
      " 7   Education                 2940 non-null   int64 \n",
      " 8   EducationField            2940 non-null   object\n",
      " 9   EnvironmentSatisfaction   2940 non-null   int64 \n",
      " 10  Gender                    2940 non-null   object\n",
      " 11  HourlyRate                2940 non-null   int64 \n",
      " 12  JobInvolvement            2940 non-null   int64 \n",
      " 13  JobLevel                  2940 non-null   int64 \n",
      " 14  JobRole                   2940 non-null   object\n",
      " 15  JobSatisfaction           2940 non-null   int64 \n",
      " 16  MaritalStatus             2940 non-null   object\n",
      " 17  MonthlyIncome             2940 non-null   int64 \n",
      " 18  MonthlyRate               2940 non-null   int64 \n",
      " 19  NumCompaniesWorked        2940 non-null   int64 \n",
      " 20  Over18                    2940 non-null   object\n",
      " 21  OverTime                  2940 non-null   object\n",
      " 22  PercentSalaryHike         2940 non-null   int64 \n",
      " 23  PerformanceRating         2940 non-null   int64 \n",
      " 24  RelationshipSatisfaction  2940 non-null   int64 \n",
      " 25  StandardHours             2940 non-null   int64 \n",
      " 26  StockOptionLevel          2940 non-null   int64 \n",
      " 27  TotalWorkingYears         2940 non-null   int64 \n",
      " 28  TrainingTimesLastYear     2940 non-null   int64 \n",
      " 29  WorkLifeBalance           2940 non-null   int64 \n",
      " 30  YearsAtCompany            2940 non-null   int64 \n",
      " 31  YearsInCurrentRole        2940 non-null   int64 \n",
      " 32  YearsSinceLastPromotion   2940 non-null   int64 \n",
      " 33  YearsWithCurrManager      2940 non-null   int64 \n",
      "dtypes: int64(25), object(9)\n",
      "memory usage: 781.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cb3ef1",
   "metadata": {
    "id": "f1f5de53"
   },
   "source": [
    "**Observations:**\n",
    "- There are 2940 observations and 34 columns.\n",
    "- All the column have 2940 non-null values i.e. there are no missing values in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138a2944",
   "metadata": {
    "id": "09b353cb"
   },
   "source": [
    "**Let's check the unique values in each column** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c381cc6",
   "metadata": {
    "id": "9b8f1776",
    "outputId": "568e3320-e9ca-4c72-e267-b6773f1461c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmployeeNumber              2940\n",
       "Attrition                      2\n",
       "Age                           43\n",
       "BusinessTravel                 3\n",
       "DailyRate                    886\n",
       "Department                     3\n",
       "DistanceFromHome              29\n",
       "Education                      5\n",
       "EducationField                 6\n",
       "EnvironmentSatisfaction        4\n",
       "Gender                         2\n",
       "HourlyRate                    71\n",
       "JobInvolvement                 4\n",
       "JobLevel                       5\n",
       "JobRole                        9\n",
       "JobSatisfaction                4\n",
       "MaritalStatus                  3\n",
       "MonthlyIncome               1349\n",
       "MonthlyRate                 1427\n",
       "NumCompaniesWorked            10\n",
       "Over18                         1\n",
       "OverTime                       2\n",
       "PercentSalaryHike             15\n",
       "PerformanceRating              2\n",
       "RelationshipSatisfaction       4\n",
       "StandardHours                  1\n",
       "StockOptionLevel               4\n",
       "TotalWorkingYears             40\n",
       "TrainingTimesLastYear          7\n",
       "WorkLifeBalance                4\n",
       "YearsAtCompany                37\n",
       "YearsInCurrentRole            19\n",
       "YearsSinceLastPromotion       16\n",
       "YearsWithCurrManager          18\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking unique values in each column\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7f22ea",
   "metadata": {
    "id": "8182513f"
   },
   "source": [
    "**Observations:**\n",
    "- Employee number is an identifier which is unique for each employee and we can drop this column as it would not add any value to our analysis.\n",
    "- Over18 and StandardHours have only 1 unique value. These column will not add any value to our model hence we can drop them.\n",
    "- On the basis of number of unique values in each column and the data description, we can identify the continuous and categorical columns in the data.\n",
    "\n",
    "Let's drop the columns mentioned above and define lists for numerical and categorical columns to apply explore them separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "245c880c",
   "metadata": {
    "id": "2b73820f"
   },
   "outputs": [],
   "source": [
    "#dropping the columns \n",
    "df=df.drop(['EmployeeNumber','Over18','StandardHours'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e8e3c72e",
   "metadata": {
    "id": "188e22ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Attrition',\n",
       " 'OverTime',\n",
       " 'BusinessTravel',\n",
       " 'Department',\n",
       " 'Education',\n",
       " 'EducationField',\n",
       " 'JobSatisfaction',\n",
       " 'EnvironmentSatisfaction',\n",
       " 'WorkLifeBalance',\n",
       " 'StockOptionLevel',\n",
       " 'Gender',\n",
       " 'PerformanceRating',\n",
       " 'JobInvolvement',\n",
       " 'JobLevel',\n",
       " 'JobRole',\n",
       " 'MaritalStatus',\n",
       " 'RelationshipSatisfaction']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating numerical columns\n",
    "num_cols=['DailyRate','Age','DistanceFromHome','MonthlyIncome','MonthlyRate','PercentSalaryHike','TotalWorkingYears',\n",
    "          'YearsAtCompany','NumCompaniesWorked','HourlyRate',\n",
    "          'YearsInCurrentRole','YearsSinceLastPromotion','YearsWithCurrManager','TrainingTimesLastYear']\n",
    "\n",
    "#Creating categorical variables \n",
    "cat_cols= ['Attrition','OverTime','BusinessTravel', 'Department','Education', 'EducationField','JobSatisfaction','EnvironmentSatisfaction','WorkLifeBalance',\n",
    "           'StockOptionLevel','Gender', 'PerformanceRating', 'JobInvolvement','JobLevel', 'JobRole', 'MaritalStatus','RelationshipSatisfaction']\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4403aaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I did the above automatically by splitting the fields according to the number of unique values, but it won't work becaues some of the catgorical fields have more than 10 values but still dealt with as categorical\n",
    "xnum_cols = pd.DataFrame(df.nunique())\n",
    "xnum_cols.loc[uniques[0]>10]\n",
    "xnum_cols = xnum_cols.index.tolist()\n",
    "\n",
    "xcat_cols = pd.DataFrame(df.nunique())\n",
    "xcat_cols.loc[uniques[0]>=10]\n",
    "xcat_cols = xcat_cols.index.tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbfcc85",
   "metadata": {
    "id": "7c1a436f"
   },
   "source": [
    "### Let's start with univariate analysis of numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "18340d58",
   "metadata": {
    "id": "fb41a488",
    "outputId": "32820b4b-fad7-48d1-a0d7-b045a8cf3bbc",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>2940.0</td>\n",
       "      <td>36.923810</td>\n",
       "      <td>9.133819</td>\n",
       "      <td>18.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DailyRate</th>\n",
       "      <td>2940.0</td>\n",
       "      <td>802.485714</td>\n",
       "      <td>403.440447</td>\n",
       "      <td>102.0</td>\n",
       "      <td>465.0</td>\n",
       "      <td>802.0</td>\n",
       "      <td>1157.0</td>\n",
       "      <td>1499.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <td>2940.0</td>\n",
       "      <td>9.192517</td>\n",
       "      <td>8.105485</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education</th>\n",
       "      <td>2940.0</td>\n",
       "      <td>2.912925</td>\n",
       "      <td>1.023991</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EnvironmentSatisfaction</th>\n",
       "      <td>2940.0</td>\n",
       "      <td>2.721769</td>\n",
       "      <td>1.092896</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HourlyRate</th>\n",
       "      <td>2940.0</td>\n",
       "      <td>65.891156</td>\n",
       "      <td>20.325969</td>\n",
       "      <td>30.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JobInvolvement</th>\n",
       "      <td>2940.0</td>\n",
       "      <td>2.729932</td>\n",
       "      <td>0.711440</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JobLevel</th>\n",
       "      <td>2940.0</td>\n",
       "      <td>2.063946</td>\n",
       "      <td>1.106752</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JobSatisfaction</th>\n",
       "      <td>2940.0</td>\n",
       "      <td>2.728571</td>\n",
       "      <td>1.102658</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <td>2940.0</td>\n",
       "      <td>6502.931293</td>\n",
       "      <td>4707.155770</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>2911.0</td>\n",
       "      <td>4919.0</td>\n",
       "      <td>8380.0</td>\n",
       "      <td>19999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MonthlyRate</th>\n",
       "      <td>2940.0</td>\n",
       "      <td>14313.103401</td>\n",
       "      <td>7116.575021</td>\n",
       "      <td>2094.0</td>\n",
       "      <td>8045.0</td>\n",
       "      <td>14235.5</td>\n",
       "      <td>20462.0</td>\n",
       "      <td>26999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumCompaniesWorked</th>\n",
       "      <td>2940.0</td>\n",
       "      <td>2.693197</td>\n",
       "      <td>2.497584</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PercentSalaryHike</th>\n",
       "      <td>2940.0</td>\n",
       "      <td>15.209524</td>\n",
       "      <td>3.659315</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PerformanceRating</th>\n",
       "      <td>2940.0</td>\n",
       "      <td>3.153741</td>\n",
       "      <td>0.360762</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RelationshipSatisfaction</th>\n",
       "      <td>2940.0</td>\n",
       "      <td>2.712245</td>\n",
       "      <td>1.081025</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StockOptionLevel</th>\n",
       "      <td>2940.0</td>\n",
       "      <td>0.793878</td>\n",
       "      <td>0.851932</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalWorkingYears</th>\n",
       "      <td>2940.0</td>\n",
       "      <td>11.279592</td>\n",
       "      <td>7.779458</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TrainingTimesLastYear</th>\n",
       "      <td>2940.0</td>\n",
       "      <td>2.799320</td>\n",
       "      <td>1.289051</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WorkLifeBalance</th>\n",
       "      <td>2940.0</td>\n",
       "      <td>2.761224</td>\n",
       "      <td>0.706356</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <td>2940.0</td>\n",
       "      <td>7.008163</td>\n",
       "      <td>6.125483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YearsInCurrentRole</th>\n",
       "      <td>2940.0</td>\n",
       "      <td>4.229252</td>\n",
       "      <td>3.622521</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <td>2940.0</td>\n",
       "      <td>2.187755</td>\n",
       "      <td>3.221882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "      <td>2940.0</td>\n",
       "      <td>4.123129</td>\n",
       "      <td>3.567529</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           count          mean          std     min     25%  \\\n",
       "Age                       2940.0     36.923810     9.133819    18.0    30.0   \n",
       "DailyRate                 2940.0    802.485714   403.440447   102.0   465.0   \n",
       "DistanceFromHome          2940.0      9.192517     8.105485     1.0     2.0   \n",
       "Education                 2940.0      2.912925     1.023991     1.0     2.0   \n",
       "EnvironmentSatisfaction   2940.0      2.721769     1.092896     1.0     2.0   \n",
       "HourlyRate                2940.0     65.891156    20.325969    30.0    48.0   \n",
       "JobInvolvement            2940.0      2.729932     0.711440     1.0     2.0   \n",
       "JobLevel                  2940.0      2.063946     1.106752     1.0     1.0   \n",
       "JobSatisfaction           2940.0      2.728571     1.102658     1.0     2.0   \n",
       "MonthlyIncome             2940.0   6502.931293  4707.155770  1009.0  2911.0   \n",
       "MonthlyRate               2940.0  14313.103401  7116.575021  2094.0  8045.0   \n",
       "NumCompaniesWorked        2940.0      2.693197     2.497584     0.0     1.0   \n",
       "PercentSalaryHike         2940.0     15.209524     3.659315    11.0    12.0   \n",
       "PerformanceRating         2940.0      3.153741     0.360762     3.0     3.0   \n",
       "RelationshipSatisfaction  2940.0      2.712245     1.081025     1.0     2.0   \n",
       "StockOptionLevel          2940.0      0.793878     0.851932     0.0     0.0   \n",
       "TotalWorkingYears         2940.0     11.279592     7.779458     0.0     6.0   \n",
       "TrainingTimesLastYear     2940.0      2.799320     1.289051     0.0     2.0   \n",
       "WorkLifeBalance           2940.0      2.761224     0.706356     1.0     2.0   \n",
       "YearsAtCompany            2940.0      7.008163     6.125483     0.0     3.0   \n",
       "YearsInCurrentRole        2940.0      4.229252     3.622521     0.0     2.0   \n",
       "YearsSinceLastPromotion   2940.0      2.187755     3.221882     0.0     0.0   \n",
       "YearsWithCurrManager      2940.0      4.123129     3.567529     0.0     2.0   \n",
       "\n",
       "                              50%      75%      max  \n",
       "Age                          36.0     43.0     60.0  \n",
       "DailyRate                   802.0   1157.0   1499.0  \n",
       "DistanceFromHome              7.0     14.0     29.0  \n",
       "Education                     3.0      4.0      5.0  \n",
       "EnvironmentSatisfaction       3.0      4.0      4.0  \n",
       "HourlyRate                   66.0     84.0    100.0  \n",
       "JobInvolvement                3.0      3.0      4.0  \n",
       "JobLevel                      2.0      3.0      5.0  \n",
       "JobSatisfaction               3.0      4.0      4.0  \n",
       "MonthlyIncome              4919.0   8380.0  19999.0  \n",
       "MonthlyRate               14235.5  20462.0  26999.0  \n",
       "NumCompaniesWorked            2.0      4.0      9.0  \n",
       "PercentSalaryHike            14.0     18.0     25.0  \n",
       "PerformanceRating             3.0      3.0      4.0  \n",
       "RelationshipSatisfaction      3.0      4.0      4.0  \n",
       "StockOptionLevel              1.0      1.0      3.0  \n",
       "TotalWorkingYears            10.0     15.0     40.0  \n",
       "TrainingTimesLastYear         3.0      3.0      6.0  \n",
       "WorkLifeBalance               3.0      3.0      4.0  \n",
       "YearsAtCompany                5.0      9.0     40.0  \n",
       "YearsInCurrentRole            3.0      7.0     18.0  \n",
       "YearsSinceLastPromotion       1.0      3.0     15.0  \n",
       "YearsWithCurrManager          3.0      7.0     17.0  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking summary statistics\n",
    "df[num_cols].describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dcbc2d",
   "metadata": {
    "id": "3fa3d39e"
   },
   "source": [
    "**Observations:**\n",
    "- **Average employee age is around 37 years**. It has a high range, from 18 years to 60, indicating good age diversity in the organization.\n",
    "- **At least 50% of the employees live within a 7 km radius** from the organization. However there are some extreme values, seeing as the maximum value is 29 km.\n",
    "- **The average monthly income of an employee is USD 6500.** It has a high range of values from 1K-20K USD, which is to be expected for any organization's income distribution. There is a big difference between the 3rd quartile value (around USD 8400) and the maximum value (nearly USD 20000), showing that the **company's highest earners have a disproportionately large income** in comparison to the rest of the employees. Again, this is fairly common in most organizations.\n",
    "- **Average salary hike of an employee is around 15%.** At least 50% of employees got a salary hike 14% or less, with the maximum salary hike being 25%.\n",
    "- Average number of years an employee is associated with the company is 7. \n",
    "- **On average, the number of years since an employee got a promotion is 2.18**. The majority of employees have been promoted since the last year."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbc6aed",
   "metadata": {
    "id": "3283a6be"
   },
   "source": [
    "Let's explore these variables in some more depth by observing their distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040b640c",
   "metadata": {
    "id": "6b1e0479",
    "outputId": "ff5338bb-e8e4-4b73-f87b-3ef683ce0059"
   },
   "outputs": [],
   "source": [
    "#creating histograms\n",
    "df[num_cols].hist(figsize=(14,14))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bbcdc4",
   "metadata": {
    "id": "ec26cfc8"
   },
   "source": [
    "**Observations:**\n",
    "\n",
    "- **The age distribution is close to a normal distribution** with the majority of employees between the ages of 25 and 50.\n",
    "\n",
    "- **The percentage salary hike is skewed to the right**, which means employees are mostly getting lower percentage salary increases.\n",
    "\n",
    "- **MonthlyIncome and TotalWorkingYears are skewed to the right**, indicating that the majority of workers are in entry / mid-level positions in the organization.\n",
    "\n",
    "- **DistanceFromHome also has a right skewed distribution**, meaning most employees live close to work but there are a few that live further away.\n",
    "\n",
    "- **On average, an employee has worked at 2.5 companies.** Most employees have worked at only 1 company.\n",
    "\n",
    "- **The YearsAtCompany variable distribution shows a good proportion of workers with 10+ years**, indicating a significant number of loyal employees at the organization. \n",
    "\n",
    "- **The YearsInCurrentRole distribution has three peaks at 0, 2, and 7.** There are a few employees that have even stayed in the same role for 15 years and more.\n",
    "\n",
    "- **The YearsSinceLastPromotion variable distribution indicates that some employees have not received a promotion in 10-15 years and are still working in the organization.** These employees are assumed to be high work-experience employees in upper-management roles, such as co-founders, C-suite employees etc.\n",
    "\n",
    "- The distributions of DailyRate, HourlyRate and MonthlyRate appear to be uniform and do not provide much information. It could be that daily rate refers to the income earned per extra day worked while hourly rate could refer to the same concept applied for extra hours worked per day. Since these rates tend to be broadly similar for multiple employees in the same department, that explains the uniform distribution they show. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca66e94",
   "metadata": {
    "id": "6e605786"
   },
   "source": [
    "### Univariate analysis for categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65134cf",
   "metadata": {
    "id": "1902184e",
    "outputId": "94897560-79b9-47f1-d61f-71d290e3c7f2"
   },
   "outputs": [],
   "source": [
    "#Printing the % sub categories of each category\n",
    "for i in cat_cols:\n",
    "    print(df[i].value_counts(normalize=True))\n",
    "    print('*'*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d95350",
   "metadata": {
    "id": "c093aae2"
   },
   "source": [
    "**Observations:**\n",
    "\n",
    "- **The employee attrition rate is 16%.**\n",
    "- **Around 28% of the employees are working overtime.** This number appears to be on the higher side, and might indicate a stressed employee work-life.\n",
    "- 71% of the employees have traveled rarely, while around 19% have to travel frequently.\n",
    "- Around 73% of the employees come from an educational background in the Life Sciences and Medical fields. \n",
    "- Over 65% of employees work in the Research & Development department of the organization.\n",
    "- **Nearly 40% of the employees have low (1) or medium-low (2) job satisfaction** and environment satisfaction in the organization, indicating that the morale of the company appears to be somewhat low.\n",
    "- **Over 30% of the employees show low (1) to medium-low (2) job involvement.** \n",
    "- Over 80% of the employees either have none or very less stock options. \n",
    "- **In terms of performance ratings, none of the employees have rated lower than 3 (excellent).** About 85% of employees have a performance rating equal to 3 (excellent), while the remaining have a rating of 4 (outstanding). This could either mean that the majority of employees are top performers, or  the more likely scenario is that the organization could be highly lenient with its performance appraisal process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b17322f",
   "metadata": {
    "id": "bdb2961d"
   },
   "source": [
    "### Bivariate and Multivariate analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391251fd",
   "metadata": {
    "id": "643dd47d"
   },
   "source": [
    "**We have analyzed different categorical and numerical variables.** \n",
    "\n",
    "**Let's now check how does attrition rate is related with other categorical variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fb7c89",
   "metadata": {
    "id": "796c2b07",
    "outputId": "1ace5a61-5f02-4c1f-87a4-f50e1688354a",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in cat_cols:\n",
    "    if i!='Attrition':\n",
    "        (pd.crosstab(df[i],df['Attrition'],normalize='index')*100).plot(kind='bar',figsize=(8,4),stacked=True)\n",
    "        plt.ylabel('Percentage Attrition %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bad7dc",
   "metadata": {
    "id": "3f91face"
   },
   "source": [
    "**Observations:**\n",
    "    \n",
    "- **Employees working overtime have more than a 30% chance of attrition**, \n",
    "which is very high compared to the 10% chance of attrition for employees who do not work extra hours.\n",
    "- As seen earlier, the majority of employees work for the R&D department. The chance of attrition there is ~15%\n",
    "- **Employees working as sales representatives have an attrition rate of around 40%** while HRs and Technicians have an attrition rate of around 25%. The sales and HR departments have higher attrition rates in comparison to an academic department like Research & Development, an observation that makes intuitive sense keeping in mind the differences in those job profiles. The high-pressure and incentive-based nature of Sales and Marketing roles may be contributing to their higher attrition rates.\n",
    "- **The lower the employee's job involvement, the higher their attrition chances appear to be, with 1-rated JobInvolvement employees attriting at 35%.** The reason for this could be that employees with lower job involvement might feel left out or less valued and have already started to explore new options, leading to a higher attrition rate.\n",
    "- **Employees at a lower job level also attrite more,** with 1-rated JobLevel employees showing a nearly 25% chance of attrition. These may be young employees who tend to explore more options in the initial stages of their careers. \n",
    "- **A low work-life balance rating clearly leads employees to attrite**; 30% of those in the 1-rated category show attrition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3c04b1",
   "metadata": {
    "id": "93b053a6"
   },
   "source": [
    "**Let's check the relationship between attrition and Numerical variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1350aacc",
   "metadata": {
    "id": "a6dbb256",
    "outputId": "b92ad475-2f23-43f7-ac41-e61702a4fc91"
   },
   "outputs": [],
   "source": [
    "#Mean of numerical variables grouped by attrition\n",
    "df.groupby(['Attrition'])[num_cols].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643edad8",
   "metadata": {
    "id": "d286e106"
   },
   "source": [
    "**Observations:**\n",
    "- **Employees leaving the company have a nearly 30% lower average income and 30% lesser work experience than those who are not.** These could be the employees looking to explore new options and/or increase their salary with a company switch. \n",
    "- **Employees showing attrition also tend to live 16% further from the office than those who are not**. The longer commute to and from work could mean they have to spend more time/money every day, and this could be leading to job dissatisfaction and wanting to leave the organization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127b4c38",
   "metadata": {
    "id": "df253009"
   },
   "source": [
    "**We have found out what kind of employees are leaving the company more.**\n",
    "\n",
    "### Let's check the relationship between different numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26905a33",
   "metadata": {
    "id": "5da1e8ed",
    "outputId": "ff2bf703-25d9-42e2-cfd2-c005e8eff08b"
   },
   "outputs": [],
   "source": [
    "#plotting the correlation between numerical variables\n",
    "plt.figure(figsize=(15,8))\n",
    "sns.heatmap(df[num_cols].corr(),annot=True, fmt='0.2f', cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea7dc33",
   "metadata": {
    "id": "231d85ef"
   },
   "source": [
    "**Observations:**\n",
    "\n",
    "- **Total work experience, monthly income, years at company and years with current manager are highly correlated with each other and with employee age** which is easy to understand as these variables show an increase with age for most employees. \n",
    "- Years at company and years in current role are correlated with years since last promotion which means that the company is not giving promotions at the right time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb97f0dc",
   "metadata": {
    "id": "62b1c31c"
   },
   "source": [
    "**Now we have explored our data. Let's build the model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb9e176",
   "metadata": {
    "id": "c87d8b8c"
   },
   "source": [
    "## Model Building - Approach\n",
    "1. Prepare data for modeling\n",
    "2. Partition the data into train and test set.\n",
    "3. Build model on the train data.\n",
    "4. Tune the model if required.\n",
    "5. Test the data on test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb3e4c4",
   "metadata": {
    "id": "9854fafc"
   },
   "source": [
    "###  Preparing data for modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12c2077",
   "metadata": {
    "id": "c73bfd10"
   },
   "source": [
    "**Creating dummy variables for categorical Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a73bc0d",
   "metadata": {
    "id": "10038cc3"
   },
   "outputs": [],
   "source": [
    "#creating list of dummy columns\n",
    "to_get_dummies_for = ['BusinessTravel', 'Department','Education', 'EducationField','EnvironmentSatisfaction', 'Gender',  'JobInvolvement','JobLevel', 'JobRole', 'MaritalStatus' ]\n",
    "\n",
    "#creating dummy variables\n",
    "df = pd.get_dummies(data = df, columns= to_get_dummies_for, drop_first= True)      \n",
    "\n",
    "#mapping overtime and attrition\n",
    "dict_OverTime = {'Yes': 1, 'No':0}\n",
    "dict_attrition = {'Yes': 1, 'No': 0}\n",
    "\n",
    "\n",
    "df['OverTime'] = df.OverTime.map(dict_OverTime)\n",
    "df['Attrition'] = df.Attrition.map(dict_attrition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a55db6a",
   "metadata": {
    "id": "8cf5d26f"
   },
   "source": [
    "**Separating the independent variables (X) and the dependent variable (Y)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a23f3c",
   "metadata": {
    "id": "76d1cc91"
   },
   "outputs": [],
   "source": [
    "#Separating target variable and other variables\n",
    "Y= df.Attrition\n",
    "X= df.drop(columns = ['Attrition'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014f09aa",
   "metadata": {
    "id": "c389ff82"
   },
   "source": [
    "### Scaling the data\n",
    "\n",
    "The independent variables in this dataset have different scales. When features have different scales from each other, there is a chance that a higher weightage will be given to features that have a higher magnitude, and they will dominate over other features whose magnitude changes may be smaller but whose percentage changes may be just as significant or even larger. This will impact the performance of our machine learning algorithm, and we do not want our algorithm to be biased towards one feature. \n",
    "\n",
    "The solution to this issue is **Feature Scaling**, i.e. scaling the dataset so as to give every transformed variable a comparable scale.\n",
    "\n",
    "In this problem, we will use the **Standard Scaler** method, which centers and scales the dataset using the Z-Score.\n",
    "\n",
    "It standardizes features by subtracting the mean and scaling it to have unit variance.\n",
    "\n",
    "The standard score of a sample x is calculated as:\n",
    "\n",
    "**z = (x - u) / s**\n",
    "\n",
    "where **u** is the mean of the training samples (zero) and **s** is the standard deviation of the training samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ca4eef",
   "metadata": {
    "id": "0e99f9cb"
   },
   "outputs": [],
   "source": [
    "#Scaling the data\n",
    "sc=StandardScaler()\n",
    "X_scaled=sc.fit_transform(X)\n",
    "X_scaled=pd.DataFrame(X_scaled, columns=X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfbe72c",
   "metadata": {
    "id": "0d508522"
   },
   "source": [
    "### Splitting the data into 70% train and 30% test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a50ad1",
   "metadata": {
    "id": "d5a7a233"
   },
   "source": [
    "Some classification problems can exhibit a large imbalance in the distribution of the target classes: for instance there could be several times more negative samples than positive samples. In such cases it is recommended to use the **stratified sampling** technique to ensure that relative class frequencies are approximately preserved in each train and validation fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20615ba2",
   "metadata": {
    "id": "96bfa6a3"
   },
   "outputs": [],
   "source": [
    "#splitting the data\n",
    "x_train,x_test,y_train,y_test=train_test_split(X_scaled,Y,test_size=0.3,random_state=1,stratify=Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5781a705",
   "metadata": {
    "id": "77645a49"
   },
   "source": [
    "### Model evaluation criterion\n",
    "\n",
    "#### The model can make two types of wrong predictions:\n",
    "1. Predicting an employee will attrite when the employee doesn't attrite\n",
    "2. Predicting an employee will not attrite and the employee actually attrites\n",
    "\n",
    "#### Which case is more important? \n",
    "* **Predicting that the employee will not attrite but the employee attrites** i.e. losing out on a valuable employee or asset. This would be considered a major miss for any employee attrition predictor, and is hence the more important case of wrong predictions.\n",
    "\n",
    "#### How to reduce this loss i.e the need to reduce False Negatives?\n",
    "* **The company would want the Recall to be maximized**, the greater the Recall, the higher the chances of minimizing false negatives. Hence, the focus should be on increasing Recall (minimizing the false negatives) or in other words identifying the true positives (i.e. Class 1) very well, so that the company can provide incentives to control attrition rate especially for top-performers. This would help in optimizing the overall project cost towards retaining the best talent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507421a7",
   "metadata": {
    "id": "67963d69"
   },
   "source": [
    "Also, let's create a function to calculate and print the classification report and confusion matrix so that we don't have to rewrite the same code repeatedly for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfba12c",
   "metadata": {
    "id": "7b305008"
   },
   "outputs": [],
   "source": [
    "#creating metric function \n",
    "def metrics_score(actual, predicted):\n",
    "    print(classification_report(actual, predicted))\n",
    "    cm = confusion_matrix(actual, predicted)\n",
    "    plt.figure(figsize=(8,5))\n",
    "    sns.heatmap(cm, annot=True,  fmt='.2f', xticklabels=['Not Attrite', 'Attrite'], yticklabels=['Not Attrite', 'Attrite'])\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac4f13d",
   "metadata": {
    "id": "38857a84"
   },
   "source": [
    "#### Building the model\n",
    "\n",
    "We will be building 4 different models:\n",
    "- **Linear Discriminant Analysis (LDA)**\n",
    "- **Quadratic Discriminant Analysis (QDA)**\n",
    "- **Logistic Regression**\n",
    "- **K Nearest Neighbors (KNN)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae90987d",
   "metadata": {
    "id": "20330dad"
   },
   "source": [
    "### Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682fe24a",
   "metadata": {
    "id": "7b4ba67c"
   },
   "source": [
    "Linear discriminant analysis (LDA) is generally used to classify patterns between two classes; however, it can be extended to classify multiple patterns. LDA assumes that all classes are linearly separable and according to this, multiple linear discrimination functions representing several hyperplanes in the feature space are created to distinguish between the classes. If there are two classes, then the LDA draws one hyperplane and projects the data onto this hyperplane in such a way as to maximize the separation of the two categories. This hyperplane is created according to two criteria considered simultaneously:\n",
    "\n",
    "- Maximizing the distance between the means of two classes;\n",
    "- Minimizing the variation between each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93b684a",
   "metadata": {
    "id": "e2658d2f",
    "outputId": "6ac6e132-e619-4e64-84b3-8ba9e4727c76",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#fitting lda model\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fb1eed",
   "metadata": {
    "id": "68727572"
   },
   "source": [
    "**Checking Model Performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb577f87",
   "metadata": {
    "id": "bda7f9e4",
    "outputId": "fc0e9e98-c87a-46f7-bb4d-0238671ece6e"
   },
   "outputs": [],
   "source": [
    "#checking model performance of lda\n",
    "y_pred_train_lda = lda.predict(x_train)\n",
    "metrics_score(y_train, y_pred_train_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a568f7",
   "metadata": {
    "id": "a871f9cb"
   },
   "source": [
    "- The reported average includes the macro average which averages the unweighted mean per label, and the weighted average i.e. averaging the support-weighted mean per label.\n",
    "- In classification, the class of interest is considered the positive class. Here, the class of interest is 1 i.e. identifying the employees at risk of attrition.\n",
    "\n",
    "**Reading the confusion matrix (clockwise):**\n",
    "\n",
    "* True Negative (Actual=0, Predicted=0): Model predicts that an employee would not attrite and the employee does not attrite \n",
    "\n",
    "* False Positive (Actual=0, Predicted=1): Model predicts that an employee would attrite but the employee does not attrite\n",
    "\n",
    "* False Negative (Actual=1, Predicted=0): Model predicts that an employee would not attrite but the employee attrites\n",
    "\n",
    "* True Positive (Actual=1, Predicted=1): Model predicts that an employee would attrite and the employee actually attrites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9267d9",
   "metadata": {
    "id": "d96c4a64"
   },
   "source": [
    "**Observations:**\n",
    "- The model is performing well in terms of accuracy.\n",
    "- The recall for class 1 is quite low, which implies that this model will not perform well in differentiating out the employees who have a high chance of leaving the company, and hence this model would not help reduce the attrition rate. \n",
    "- The model is giving a decent average recall. A recall of ~0.75 suggests that there is a 25% (1 - 0.75) chance that the model will predict that a person is going to leave even though he/she would not, and the company would waste their time and energy on these employees who are not at risk of attrition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea72be4",
   "metadata": {
    "id": "321f2eaf"
   },
   "source": [
    "We have built the LDA model. \n",
    "\n",
    "**Now, let's check the coefficients and find which variables are leading to attrition and which can help to reduce the attrition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3a7e2e",
   "metadata": {
    "id": "b444b77b",
    "outputId": "cfd70699-c5fc-437e-9760-c3dde4af1ef2"
   },
   "outputs": [],
   "source": [
    "#creating list of column names\n",
    "cols=X.columns\n",
    "\n",
    "#saving coefficients of lda model\n",
    "coef_lda=lda.coef_\n",
    "\n",
    "#printing the cofficients of lda\n",
    "pd.DataFrame(coef_lda,columns=cols).T.sort_values(by=0,ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a0d0ca",
   "metadata": {
    "id": "24ca3b21"
   },
   "source": [
    "**Some features which positively affect the Attrition rate are:**\n",
    "- OverTime\n",
    "- Department_Research & Development \n",
    "- BusinessTravel_Travel_Frequently\n",
    "- Department_Sales\n",
    "- MaritalStatus_Single \n",
    "- BusinessTravel_Travel_Rarely\n",
    "- NumCompaniesWorked\n",
    "- YearsSinceLastPromotion\t\n",
    "- JobRole_Human Resources\t\n",
    "- JobRole_Sales Executive\t\n",
    "- YearsAtCompany\n",
    "- DistanceFromHome\n",
    "\n",
    "**Some features which negatively affect the Attrition rate are:**\n",
    "- JobInvolvement_3\n",
    "- EducationField_Life Sciences\t\n",
    "- JobInvolvement_2\n",
    "- MonthlyIncome\n",
    "- EducationField_Medical\t\n",
    "- JobInvolvement_4\t\n",
    "- JobLevel_2\n",
    "- EnvironmentSatisfaction_4\t\n",
    "- EnvironmentSatisfaction_3\n",
    "- EnvironmentSatisfaction_2\t\n",
    "- JobSatisfaction\t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd604af1",
   "metadata": {
    "id": "jZL4An5c_9es"
   },
   "source": [
    "**Observations:**\n",
    "\n",
    "- Based on the LDA model, **Overtime is the most important feature** in detecting whether an employee would attrite or not.\n",
    "- **This model also suggests that attrition is dependent on the employee's department.** Belonging to Sales or HR is shown to have a higher attrition rate which is understood, but the model also seems to suggest belonging to R&D contributes to a higher attrition rate, which is counter-intuitive. This could be because more than 65% of the employees are working in R&D, so the absolute number of employees who attrite from the company working in R&D will be significant even with a lower percentage. This is an example of the Simpson's paradox, and is evidence that a more powerful non-linear model may be necessary to accurately map the relationship between Department_Research & Development and the target variable. \n",
    "- **Business traveling is an important variable in predicting the attrition rate.** Employees who either travel a lot or travel rarely have high attrition rate. This could be because those who travel often might feel overworked and dissatisfied with their role, whereas employees traveling rarely (in an organization where nearly 90% of all employees are traveling) could be a sign of them feeling undervalued and disinterested and hence attriting more.\n",
    "- **The number of companies the employee has worked for in the past also appears to impact the likelihood of attrition** - the greater the number the higher the chance the employee will attrite. This suggests that employees who have worked for a higher number of companies may probably not stay loyal and may continue switching companies.\n",
    "- Other features which appear to affect the chances of attrition are the number of years at the current company and the distance from home, both with positive correlations to attrition likelihood.\n",
    "- The Job Involvement features being negatively correlated with attrition signify that **employees who are more involved in their jobs tend to attrite less.** This could probably be because a high degree of job involvement might make employees feel they are more important to the company, and hence discourage them from attrition.\n",
    "- The model also captures the **inverse relation between income and attrition** - suggesting attrition rates can be controlled by increasing employee salary.\n",
    "-  **Employees who are satisfied with the environment and culture of the organization show a lower chance of attrition**, a conclusion that makes sense since a good work environment is likely to keep employees happy and prevent them from attriting.\n",
    "- **Employees with higher total work experience and a good position in the organization are also less likely to attrite**, probably because working at the organization for several years and/or occupying a good position tends to promote job stability and discourages volatility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ada24d3",
   "metadata": {
    "id": "fdb458e1"
   },
   "source": [
    "#### Precision-Recall Curve for LDA\n",
    "\n",
    "**Precision-Recall curves summarize the trade-off between the true positive rate and the positive predictive value for a predictive model using different probability thresholds.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe6ce09",
   "metadata": {
    "id": "1d7d2894",
    "outputId": "cda7d7b5-f294-461a-c2dc-90c561f89d76"
   },
   "outputs": [],
   "source": [
    "y_scores_lda=lda.predict_proba(x_train) #predict_proba gives the probability of each observation belonging to each class\n",
    "\n",
    "\n",
    "precisions_lda, recalls_lda, thresholds_lda = precision_recall_curve(y_train, y_scores_lda[:,1])\n",
    "\n",
    "#Plot values of precisions, recalls, and thresholds\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(thresholds_lda, precisions_lda[:-1], 'b--', label='precision')\n",
    "plt.plot(thresholds_lda, recalls_lda[:-1], 'g--', label = 'recall')\n",
    "plt.xlabel('Threshold')\n",
    "plt.legend(loc='upper left')\n",
    "plt.ylim([0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1498be",
   "metadata": {
    "id": "8c3b87cd"
   },
   "source": [
    "**Observation:**\n",
    "- We can see that precision and recall are balanced for a threshold of about ~0.35."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0b7ae4",
   "metadata": {
    "id": "2f4523c6"
   },
   "source": [
    "**Let's check the model performance at this threshold**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8e3c89",
   "metadata": {
    "id": "a9f5e56f",
    "outputId": "8519c78b-4581-4d28-9c9c-70652d5a64fb"
   },
   "outputs": [],
   "source": [
    "optimal_threshold1=.35\n",
    "y_pred_train_lda = lda.predict_proba(x_train)\n",
    "metrics_score(y_train, y_pred_train_lda[:,1]>optimal_threshold1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee58f134",
   "metadata": {
    "id": "153db513"
   },
   "source": [
    "**Observation**\n",
    "- The precision has dropped but **the recall for class 1 has increased to 0.60**; the class and metric of interest here.\n",
    "- **The model is able to identify the majority of employees who are at risk of attrition,** and would hence be a more useful model than the previous iteration with the default threshold.\n",
    "\n",
    "Let's check the model performance on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ba0cbe",
   "metadata": {
    "id": "dfe45211",
    "outputId": "f6b8508f-00a5-4bfa-aa4b-ad8b229edab5"
   },
   "outputs": [],
   "source": [
    "optimal_threshold1=.35\n",
    "y_pred_test_lda = lda.predict_proba(x_test)\n",
    "metrics_score(y_test, y_pred_test_lda[:,1]>optimal_threshold1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a804d0e",
   "metadata": {
    "id": "5e82f11b"
   },
   "source": [
    "**Observation:**\n",
    "- The model is giving **similar performance on the test and train data**, meaning the model has generalized well.\n",
    "- **The average recall and precision for the model are good**, but let's see if we can get a better performance using other algorithms. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e6f01a",
   "metadata": {
    "id": "25142e0a"
   },
   "source": [
    "### Quadratic Discriminant Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85741508",
   "metadata": {
    "id": "98a4d421"
   },
   "source": [
    "Quadratic discriminant analysis (QDA) is a probabilistic parametric classification technique which represents an evolution of LDA for nonlinear class separations. QDA, like LDA, is based on the hypothesis that the probability density distributions are multivariate normal but, in this case, the dispersion is not the same for all of the categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48dd8ff",
   "metadata": {
    "id": "47253a63",
    "outputId": "30143ea7-a604-4261-e061-4975cb2613c3"
   },
   "outputs": [],
   "source": [
    "#fitting qda model\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qda.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56649176",
   "metadata": {
    "id": "21f5948e",
    "outputId": "35ec3310-6771-4d43-9a03-2a23f83e78d1"
   },
   "outputs": [],
   "source": [
    "#checking model performance on the training data\n",
    "y_pred_train_qda = qda.predict(x_train)\n",
    "metrics_score(y_train, y_pred_train_qda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9a7a00",
   "metadata": {
    "id": "d78c654f",
    "outputId": "a7d06170-e3e4-41d5-feb0-e841065be3da"
   },
   "outputs": [],
   "source": [
    "#checking performance of the model on the test data\n",
    "y_pred_test_qda = qda.predict(x_test)\n",
    "metrics_score(y_test, y_pred_test_qda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f5798f",
   "metadata": {
    "id": "0d67cebc"
   },
   "source": [
    "**Observations:**\n",
    "\n",
    "- QDA gives a very high recall for class 1 but the recall for class 0 is very poor which makes the **overall recall and accuracy very low**.\n",
    "- **The model has a high number of false positives**, i.e the model will predict that the employee would leave even though he/she would not.\n",
    "- This is a poor model that will be of no use to the company.\n",
    "\n",
    "Let's move on to another model - Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff94e3f",
   "metadata": {
    "id": "1de66d84"
   },
   "source": [
    "### Logistic Regression Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da6dab0",
   "metadata": {
    "id": "2a192a78"
   },
   "source": [
    "- Logistic Regression is a supervised learning algorithm which is used for **binary classification problems** i.e. where the dependent variable is categorical and has only two possible values. In logistic regression, we use the sigmoid function to calculate the probability of an event y, given some features x as:\n",
    "\n",
    "                                          P(y)=1/exp(1 + exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf357d46",
   "metadata": {
    "id": "1c3fec96",
    "outputId": "9bca79ca-b15a-4868-e3b2-dbf62e54fd14"
   },
   "outputs": [],
   "source": [
    "#fitting logistic regression model\n",
    "lg=LogisticRegression()\n",
    "lg.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c658e7",
   "metadata": {
    "id": "f45ec38a"
   },
   "source": [
    "**Checking model performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acd2d45",
   "metadata": {
    "id": "9a3062aa",
    "outputId": "a41ccb8d-7640-4ab5-d4da-5fd22c1edce5"
   },
   "outputs": [],
   "source": [
    "#checking the performance on the training data\n",
    "y_pred_train = lg.predict(x_train)\n",
    "metrics_score(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76357b2f",
   "metadata": {
    "id": "218089fd",
    "outputId": "62a94942-8b29-4459-c315-39e22b6e201d"
   },
   "outputs": [],
   "source": [
    "#checking the performance on the test dataset\n",
    "y_pred_test = lg.predict(x_test)\n",
    "metrics_score(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737ea415",
   "metadata": {
    "id": "382c8e52"
   },
   "source": [
    "**Observations:**\n",
    "- **We are getting an accuracy of around 90%** on train and test dataset.\n",
    "- However, **the recall for this model is only around 50% for class 1 on train and 46% on test.**\n",
    "- As the recall is low, **this model will not perform well** in differentiating out those employees who have a high chance of leaving the company, meaning it will eventually not help in reducing the attrition rate. \n",
    "- As we can see from the Confusion Matrix, **this model fails to identify the majority of employees who are at risk of attrition.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a5d2c3",
   "metadata": {
    "id": "dc744c23"
   },
   "source": [
    "**Let's check the coefficients and find which variables are leading to attrition and which can help to reduce the attrition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c6a58b",
   "metadata": {
    "id": "82beae47",
    "outputId": "ced49131-018c-47b9-b523-a1ec728ea249"
   },
   "outputs": [],
   "source": [
    "#printing the coefficients of logistic regression\n",
    "cols=X.columns\n",
    "\n",
    "coef_lg=lg.coef_\n",
    "\n",
    "pd.DataFrame(coef_lg,columns=cols).T.sort_values(by=0,ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2abf192",
   "metadata": {
    "id": "163545b6"
   },
   "source": [
    "**Observations:**\n",
    "\n",
    "\n",
    "**Features which positively affect on the attrition rate are:**\n",
    "- OverTime\t\n",
    "- BusinessTravel_Travel_Frequently\t\n",
    "- Department_Research & Development\t\n",
    "- JobRole_Sales Executive\t\n",
    "- MaritalStatus_Single\t\n",
    "- Department_Sales\t\n",
    "- NumCompaniesWorked\t\n",
    "- YearsSinceLastPromotion\n",
    "- JobLevel_5\t\n",
    "- BusinessTravel_Travel_Rarely\n",
    "- DistanceFromHome\n",
    "- YearsAtCompany\t\n",
    "- JobRole_Human Resources\t\n",
    "- JobRole_Sales Representative\n",
    "\n",
    "**Features which negatively affect on the attrition rate are:**\n",
    "- MonthlyIncome\t\n",
    "- JobInvolvement_3\t\n",
    "- JobLevel_2\t\n",
    "- EnvironmentSatisfaction_4\t\n",
    "- JobInvolvement_4\t\n",
    "- JobInvolvement_2\t\n",
    "- EnvironmentSatisfaction_3\t\n",
    "- EducationField_Life Sciences\t\n",
    "- EnvironmentSatisfaction_2\t\n",
    "- YearsWithCurrManager\t\n",
    "- JobRole_Research Director\t\n",
    "- TotalWorkingYears\t\n",
    "- JobSatisfaction\t\n",
    "\n",
    "**The coefficients which are positively and negatively affecting the attrition rate seem to be quite similar for logistic regression and LDA. This means they are capturing the same pattern and giving nearly the same conclusions from the dataset.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd72cc8",
   "metadata": {
    "id": "4291d05e"
   },
   "source": [
    "The coefficients of the logistic regression model give us the log of odds, which is hard to interpret in the real world. We can convert the log of odds into real odds by taking its exponential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2253d431",
   "metadata": {
    "id": "9d48313b",
    "outputId": "33a2e695-0f22-400e-f8b8-1827c63821da"
   },
   "outputs": [],
   "source": [
    "odds = np.exp(lg.coef_[0]) #finding the odds\n",
    "\n",
    "# adding the odds to a dataframe and sorting the values\n",
    "pd.DataFrame(odds, x_train.columns, columns=['odds']).sort_values(by='odds', ascending=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d5aebc",
   "metadata": {
    "id": "8f068e40"
   },
   "source": [
    "**Observations**\n",
    "- The odds of an employee working overtime to attrite are **2.6 times** the odds of one who is not, probably due to the fact that working overtime is not sustainable for an extended duration for any employee, and may lead to burnout and job dissatisfaction.\n",
    "- The odds of an employee traveling frequently to attrite are **double** the odds of an employee who doesn't travel as often.\n",
    "- The odds of single employees attriting are **1.8 times (80% higher than)** the odds of an employee with another marital status."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba44a34",
   "metadata": {
    "id": "991566fe"
   },
   "source": [
    "**Precision-Recall Curve for logistic regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a2e363",
   "metadata": {
    "id": "9ee22ec1",
    "outputId": "b8f98181-3e96-4fc1-d0e5-aab4f68c1140"
   },
   "outputs": [],
   "source": [
    "y_scores_lg=lg.predict_proba(x_train) #predict_proba gives the probability of each observation belonging to each class\n",
    "\n",
    "\n",
    "precisions_lg, recalls_lg, thresholds_lg = precision_recall_curve(y_train, y_scores_lg[:,1])\n",
    "\n",
    "#Plot values of precisions, recalls, and thresholds\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(thresholds_lg, precisions_lg[:-1], 'b--', label='precision')\n",
    "plt.plot(thresholds_lg, recalls_lg[:-1], 'g--', label = 'recall')\n",
    "plt.xlabel('Threshold')\n",
    "plt.legend(loc='upper left')\n",
    "plt.ylim([0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f5715d",
   "metadata": {
    "id": "da12cf85"
   },
   "source": [
    "**Observation:**\n",
    "- We can see that precision and recall are balanced for a threshold of about ~**0.35**.\n",
    "\n",
    "**Let's find out the performance of the model at this threshold**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364cb15b",
   "metadata": {
    "id": "5611de61",
    "outputId": "fb449d75-16a7-4319-9a6a-f5f0b042f94b"
   },
   "outputs": [],
   "source": [
    "optimal_threshold1=.35\n",
    "y_pred_train = lg.predict_proba(x_train)\n",
    "metrics_score(y_train, y_pred_train[:,1]>optimal_threshold1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bfb9af",
   "metadata": {
    "id": "e048d817"
   },
   "source": [
    "**Observations**\n",
    "- **The model performance has improved. The recall has increased significantly for class 1.**\n",
    "- Let's check the performance on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f752c7",
   "metadata": {
    "id": "914fc850",
    "outputId": "8ff54ff5-1dde-430b-c342-a415c20ca9c4"
   },
   "outputs": [],
   "source": [
    "optimal_threshold1=.35\n",
    "y_pred_test = lg.predict_proba(x_test)\n",
    "metrics_score(y_test, y_pred_test[:,1]>optimal_threshold1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a32522",
   "metadata": {
    "id": "c53367ce"
   },
   "source": [
    "**Observation:**\n",
    "- The model is giving **similar performance on the test and train data** i.e. the model is giving a generalized performance.\n",
    "- **The recall of the test data has increased significantly** while at the same time, the precision has decreased, which is to be expected while adjusting the threshold.\n",
    "- The average recall and precision for the model are good but let's see if we can get better performance using other algorithms. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2c99db",
   "metadata": {
    "id": "a61f49ee"
   },
   "source": [
    "### K- Nearest Neighbors (KNN) Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbb25b3",
   "metadata": {
    "id": "0fb5417c"
   },
   "source": [
    "KNN uses similar features to predict the values of new data points, which means the new data point will be assigned a value based on how similar it is to the data points in the training set. \n",
    "\n",
    "\n",
    "The following steps are performed in KNN:\n",
    "\n",
    "- Select K\n",
    "- Calculate distance (Euclidean, Manhattan, etc.)\n",
    "- Find the K closest neighbors\n",
    "- Vote for labels\n",
    "\n",
    "The “K” in the KNN algorithm is the nearest neighbor we wish to take the vote from. Generally, K is taken to be an odd number when the no. of classes are even, so as to get a majority vote. Let's say K = 3. In that case, we will make a circle with the new data point as the center just as big as enclosing only the three nearest data points on the plane.\n",
    "\n",
    "**But before actually building the model, we need to identify the value of K to be used in KNN. We will perform the following steps for the same.**\n",
    "\n",
    "- For every value of K (from 1 to 15), split the train set into new train and validation set (30 times)\n",
    "- Scale the training data and validation data\n",
    "- Take the average of the error on these train and the validation sets for each K\n",
    "- Plot the average train vs the validation set error for all Ks \n",
    "- Choose a suitable K from the plot where the two errors are comparable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3008b449",
   "metadata": {
    "id": "29b49ff1",
    "outputId": "0e85bbda-760a-4b3e-c4d8-ddfbc398d364"
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# We select the best value of k for which the error rate is the least in the validation data\n",
    "# Let us loop over a few values of k to determine the best k\n",
    "\n",
    "train_error = []\n",
    "test_error = []\n",
    "knn_many_split = {}\n",
    "\n",
    "error_df_knn = pd.DataFrame()\n",
    "features = X.columns\n",
    "\n",
    "for k in range(1,15):\n",
    "    train_error = []\n",
    "    test_error = []\n",
    "    lista = []\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    for i in range(30):\n",
    "        x_train_new, x_val, y_train_new, y_val = train_test_split(x_train, y_train, test_size = 0.20)\n",
    "    \n",
    "        #Fitting knn on training data\n",
    "        knn.fit(x_train_new, y_train_new)\n",
    "        #Calculating error on training and validation data\n",
    "        train_error.append(1 - knn.score(x_train_new, y_train_new)) \n",
    "        test_error.append(1 - knn.score(x_val, y_val))\n",
    "    lista.append(sum(train_error)/len(train_error))\n",
    "    lista.append(sum(test_error)/len(test_error))\n",
    "    knn_many_split[k] = lista\n",
    "\n",
    "knn_many_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a788d206",
   "metadata": {
    "id": "e73266d5",
    "outputId": "d306a885-0436-4008-9e2c-bd88cea1d95f"
   },
   "outputs": [],
   "source": [
    "kltest = []\n",
    "vltest = []\n",
    "for k, v in knn_many_split.items():\n",
    "    kltest.append(k)\n",
    "    vltest.append(knn_many_split[k][1])\n",
    "\n",
    "kltrain = []\n",
    "vltrain = []\n",
    "\n",
    "for k, v in knn_many_split.items():\n",
    "    kltrain.append(k)\n",
    "    vltrain.append(knn_many_split[k][0])\n",
    "\n",
    "# Plotting k vs error\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(kltest,vltest, label = 'test' )\n",
    "plt.plot(kltrain,vltrain, label = 'train')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110752bd",
   "metadata": {
    "id": "6e221421"
   },
   "source": [
    "**Observations:**\n",
    "- We can see that the test error is more or less similar for K greater than or equal to 5. But the train error keeps increasing with increasing K.\n",
    "- This implies that we would get a lower train and test error if we choose K = 5. Also, if we choose a high value of K, the model would get biased due to the imbalance in the dataset.\n",
    "- So, let's fit the KNN model with **K = 5** on the entire training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfbca12",
   "metadata": {
    "id": "e7a34d15"
   },
   "outputs": [],
   "source": [
    "#define knn model\n",
    "knn=KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6544245",
   "metadata": {
    "id": "33ec33a2",
    "outputId": "7438291a-25df-472c-daef-67302c35ce56"
   },
   "outputs": [],
   "source": [
    "#fitting data to the KNN model\n",
    "knn.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164ba88f",
   "metadata": {
    "id": "3c5ff6f9",
    "outputId": "9d579ef4-a0ed-4743-eae8-e36290d39dca"
   },
   "outputs": [],
   "source": [
    "#checking the performance of knn model\n",
    "y_pred_train_knn = knn.predict(x_train)\n",
    "metrics_score(y_train, y_pred_train_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63714b4",
   "metadata": {
    "id": "89076d10",
    "outputId": "3a5cfc95-4c95-442b-83bd-d1ab1aac49d9"
   },
   "outputs": [],
   "source": [
    "y_pred_test_knn = knn.predict(x_test)\n",
    "metrics_score(y_test, y_pred_test_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b97506",
   "metadata": {
    "id": "dffaa988"
   },
   "source": [
    "**Observations:**\n",
    "- The model gives a similar performance on the train and test data but the **recall is not very good**. Let's see if we can improve on that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719b00e5",
   "metadata": {
    "id": "6d2a78d6"
   },
   "source": [
    "**Let's try to fine tune this model and check if we could increase the Recall.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de64c41",
   "metadata": {
    "id": "04a4742d"
   },
   "source": [
    "### Using GridSearchCV for Hyperparameter tuning model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685b4c04",
   "metadata": {
    "id": "9d503ec1"
   },
   "source": [
    "* Hyperparameter tuning is tricky in the sense that there is no direct way to calculate how a change in the hyperparameter value will reduce the loss of your model, so we usually resort to experimentation.\n",
    "* **Grid search** is a tuning technique that attempts to compute the optimum values of hyperparameters. \n",
    "* It is an exhaustive search that is performed on specific parameter values of a model.\n",
    "* The parameters of the estimator/model used to apply these methods are optimized by cross-validated grid-search over a parameter grid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b89067",
   "metadata": {
    "id": "fa4c32d9"
   },
   "source": [
    "- **n_neighbors**\n",
    "\n",
    "    - Number of neighbors to use.\n",
    "\n",
    "\n",
    "- **weights={'uniform', 'distance'}**\n",
    "    - uniform : uniform weights. All points in each neighborhood are weighted equally.\n",
    "    - distance : weight points by the inverse of their distance. In this case, the closer neighbors of a query point will have a greater influence than neighbors which are further away.\n",
    "\n",
    "\n",
    "- **p**\n",
    "    - When p = 1, this is equivalent to using Manhattan_distance (L1), and Euclidean_distance (L2) is used for p = 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5669012c",
   "metadata": {
    "id": "a1028eb8",
    "outputId": "9e6b046a-91b5-46bd-e055-d21e9e2069d8"
   },
   "outputs": [],
   "source": [
    "params_knn={'n_neighbors':np.arange(3,15),'weights':['uniform','distance'],'p':[1,2]}\n",
    "\n",
    "grid_knn=GridSearchCV(estimator=knn,param_grid=params_knn,scoring='recall',cv=10)\n",
    "\n",
    "model_knn=grid_knn.fit(x_train,y_train)\n",
    "\n",
    "knn_estimator = model_knn.best_estimator_\n",
    "print(knn_estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c1e81e",
   "metadata": {
    "id": "24caa73f"
   },
   "source": [
    "- The best hyperparameters for the KNN classifier are n_neighbors=3, weights='distance', and p=1\n",
    "\n",
    "**Let's use these parameters to build the new KNN model and find the recall of that model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55712f1b",
   "metadata": {
    "id": "0829b7ce",
    "outputId": "6ba8f785-a462-4692-a979-60ada08ef21c"
   },
   "outputs": [],
   "source": [
    "#Fit the best estimator on the training data\n",
    "knn_estimator.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8d3c31",
   "metadata": {
    "id": "4f7e2cfc",
    "outputId": "0a7eacf4-32ee-4ca9-d3a1-14df6a786f8a"
   },
   "outputs": [],
   "source": [
    "y_pred_train_knn_estimator = knn_estimator.predict(x_train)\n",
    "metrics_score(y_train, y_pred_train_knn_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb1c812",
   "metadata": {
    "id": "455946fd",
    "outputId": "dc021d91-5080-4341-c4b8-592aef359640"
   },
   "outputs": [],
   "source": [
    "y_pred_test_knn_estimator = knn_estimator.predict(x_test)\n",
    "metrics_score(y_test, y_pred_test_knn_estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a05f575",
   "metadata": {
    "id": "5cecd709"
   },
   "source": [
    "**Observations:**\n",
    "- This model seems to be overfitting but **the results have significantly improved** in comparison to previous models.\n",
    "- **Test recall and precision have greatly increased** by tuning the KNN classifier.\n",
    "- This appears to be a high-performing model that the company can use to help control the attrition rate. There is about an **83% chance** that the model will detect employees who are likely to leave the company, and the company will hence be able to take the appropriate action."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903e201c",
   "metadata": {
    "id": "4663b361"
   },
   "source": [
    "### Conclusion and Recommendations "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43daec3d",
   "metadata": {
    "id": "a2cb3e9a"
   },
   "source": [
    "**Conclusions:**\n",
    "\n",
    "- We have tried multiple models and were **able to identify the key factors involved with high attrition** in the organization.\n",
    "- The final model - **a hyperparameter-tuned KNN classifier**, is overfitting on the training dataset but **gives the highest recall on the training and the testing data.** It may be possible to further try and tune the model, and the HR department can use this model to predict whether an employee is at risk of attrition or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdd2b7c",
   "metadata": {
    "id": "a3f2c62d"
   },
   "source": [
    "**Recommendations:**\n",
    "\n",
    "- We saw that **working overtime is the most important driver of attrition.** The organization should manage their work more efficiently so that employees don't have to work overtime and can manage to have a work-life balance, or failing this, the company could provide some additional incentives to employees who are working overtime in order to retain them.\n",
    "- The organization should focus on the employees who are working in **sales and marketing** as **the attrition rate is quite high for these departments.** Perhaps the organization could look into their incentive schemes and try to come up with better ideas to retain these employees. \n",
    "- As observed earlier, **the organization has a lower percentage salary hike and promotions are given less frequently.** The company might be able to focus on giving promotions more frequently or that could increase the annual appraisal hike to incentivize employees to stay.\n",
    "- **A higher monthly income might lower the odds of an employee attriting.** The company should make sure that all its employees are compensated at least based on industry standards.\n",
    "- We observed that **approximately 40% of employees have given a poor rating on job satisfaction and environment satisfaction** , possibly contributing to a higher attrition rate. The organization should focus on improving the culture and environment of the organization by coming up with new ideas to make the office environment more open and friendly.\n",
    "- **Distance from home is also an important factor for attrition** - employees traveling a greater distance to reach the workplace are more likely to attrite. For such employees, the company could provide shuttle facilities so that the commute for such employees gets easier.\n",
    "- The data and the model suggest that **lower job involvement leads to a higher likelihood of attrition**. This might be due to a lack of growth opportunities or a poor management style. A more pro-active, hands-on approach may be required from the managers in the organization.\n",
    "- **Young and relatively new/inexperienced employees tend to show a higher attrition rate.** The organization might be able to keep track of the problems that employees with less experience face in a better manner and come up with better ideas on how the management might help them. This may help create a healthier, more welcoming environment for younger employees.\n",
    "- The organization could come up with a revised CTC plan that includes stock options for a larger proportion of the employees in order to keep them motivated."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "d6700f10",
    "91a960cf",
    "f367a777",
    "38857a84"
   ],
   "name": "Employee Attrition (1).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
